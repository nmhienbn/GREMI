{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-16T04:00:54.837500Z",
     "iopub.status.busy": "2025-02-16T04:00:54.837289Z",
     "iopub.status.idle": "2025-02-16T04:01:02.105353Z",
     "shell.execute_reply": "2025-02-16T04:01:02.104048Z",
     "shell.execute_reply.started": "2025-02-16T04:00:54.837478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio torch-geometric scikit-learn numpy pandas matplotlib seaborn tqdm easydict -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T04:01:02.106962Z",
     "iopub.status.busy": "2025-02-16T04:01:02.106610Z",
     "iopub.status.idle": "2025-02-16T04:01:07.237297Z",
     "shell.execute_reply": "2025-02-16T04:01:07.236258Z",
     "shell.execute_reply.started": "2025-02-16T04:01:02.106937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T04:01:07.239409Z",
     "iopub.status.busy": "2025-02-16T04:01:07.238710Z",
     "iopub.status.idle": "2025-02-16T04:01:07.243141Z",
     "shell.execute_reply": "2025-02-16T04:01:07.242143Z",
     "shell.execute_reply.started": "2025-02-16T04:01:07.239367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# loaded_data = torch.load('/kaggle/input/gremi-ori/BRCA/data.pt')\n",
    "# print(loaded_data.keys())\n",
    "\n",
    "# for key in loaded_data.keys():\n",
    "#     print(key)\n",
    "#     print(loaded_data[key].shape)\n",
    "#     print(loaded_data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.nn import global_mean_pool as gap\n",
    "from torch.nn import LayerNorm, Parameter\n",
    "from torch.nn import init, Parameter\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from typing import Dict\n",
    "\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def xavier_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.clf = nn.Sequential(nn.Linear(in_dim, out_dim))\n",
    "        self.clf.apply(xavier_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.clf(x)\n",
    "        return x\n",
    "\n",
    "class Fusion(nn.Module):\n",
    "    def __init__(self, num_class, num_views, hidden_dim, dropout, in_dim, dim1, dim2, dim3, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.gat1 = GAT(dropout=0.5, alpha=alpha, dim=dim1)\n",
    "        self.gat2 = GAT(dropout=0.5, alpha=alpha, dim=dim2)\n",
    "        self.gat3 = GAT(dropout=0.5, alpha=alpha, dim=dim3)\n",
    "\n",
    "        self.views = len(in_dim)\n",
    "        self.classes = num_class\n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.FeatureInforEncoder = nn.ModuleList([LinearLayer(in_dim[view], in_dim[view]) for view in range(self.views)])\n",
    "        self.TCPConfidenceLayer = nn.ModuleList([LinearLayer(hidden_dim[0], 1) for _ in range(self.views)])\n",
    "        self.TCPClassifierLayer = nn.ModuleList([LinearLayer(hidden_dim[0], num_class) for _ in range(self.views)])\n",
    "\n",
    "        self.MMClasifier = []\n",
    "        for layer in range(1, len(hidden_dim) - 1):\n",
    "            self.MMClasifier.append(LinearLayer(self.views * hidden_dim[0], hidden_dim[layer]))\n",
    "            self.MMClasifier.append(nn.ReLU())\n",
    "            self.MMClasifier.append(nn.Dropout(p=dropout))\n",
    "        if len(self.MMClasifier):\n",
    "            self.MMClasifier.append(LinearLayer(hidden_dim[-1], num_class))\n",
    "        else:\n",
    "            self.MMClasifier.append(LinearLayer(self.views * hidden_dim[-1], num_class))\n",
    "        self.MMClasifier = nn.Sequential(*self.MMClasifier)\n",
    "\n",
    "\n",
    "    def forward(self, omic1, omic2, omic3, adj1, adj2, adj3, label=None, infer=False):\n",
    "        output1, gat_output1 = self.gat1(omic1, adj1)\n",
    "        output2, gat_output2 = self.gat2(omic2, adj2)\n",
    "        output3, gat_output3 = self.gat3(omic3, adj3)\n",
    "        #\n",
    "        feature = dict()\n",
    "        feature[0], feature[1], feature[2] = output1, output2, output3\n",
    "        #\n",
    "        criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        #\n",
    "        FeatureInfo, TCPLogit, TCPConfidence = dict(), dict(), dict()\n",
    "        for view in range(self.views):\n",
    "            feature[view] = F.relu(feature[view])\n",
    "            feature[view] = F.dropout(feature[view], self.dropout, training=self.training)\n",
    "            TCPLogit[view] = self.TCPClassifierLayer[view](feature[view])\n",
    "            TCPConfidence[view] = self.TCPConfidenceLayer[view](feature[view])\n",
    "            feature[view] = feature[view] * TCPConfidence[view]\n",
    "\n",
    "        MMfeature = torch.cat([i for i in feature.values()], dim=1)\n",
    "        MMlogit = self.MMClasifier(MMfeature)\n",
    "        if infer:\n",
    "            return MMlogit\n",
    "        MMLoss = torch.mean(criterion(MMlogit, label))\n",
    "        print(torch.unique(gat_output1))\n",
    "        loss_gat1 = loss_function(gat_output1,label)\n",
    "        loss_gat2 = loss_function(gat_output2,label)\n",
    "        loss_gat3 = loss_function(gat_output3,label)\n",
    "        gat_loss = dict()\n",
    "        gat_loss[0], gat_loss[1], gat_loss[2] = loss_gat1, loss_gat2, loss_gat3\n",
    "        for view in range(self.views):\n",
    "            MMLoss = MMLoss + gat_loss[view]\n",
    "            pred = F.softmax(TCPLogit[view], dim=1)\n",
    "            p_target = torch.gather(input=pred, dim=1, index=label.unsqueeze(dim=1)).view(-1)\n",
    "            confidence_loss = torch.mean(\n",
    "                F.mse_loss(TCPConfidence[view].view(-1), p_target) + criterion(TCPLogit[view], label))\n",
    "            MMLoss = MMLoss + confidence_loss\n",
    "        return MMLoss, MMlogit, gat_output1, gat_output2, gat_output3, output1, output2, output3\n",
    "\n",
    "    def infer(self, omic1, omic2, omic3, adj1, adj2, adj3):\n",
    "        MMlogit = self.forward(omic1, omic2, omic3, adj1, adj2, adj3, infer=True)\n",
    "        return MMlogit\n",
    "\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, dropout, alpha, dim):\n",
    "\n",
    "        super(GAT, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.act = define_act_layer(act_type='none')\n",
    "        self.dim = dim\n",
    "        self.nhids = [8, 16, 12]\n",
    "        self.nheads = [4, 3, 4]\n",
    "        self.fc_dim = [600, 256, 64, 32]\n",
    "\n",
    "        self.attentions1 = [GraphAttentionLayer(\n",
    "            1, self.nhids[0], dropout=dropout, alpha=alpha, concat=True) for _ in range(self.nheads[0])]\n",
    "        for i, attention1 in enumerate(self.attentions1):\n",
    "            self.add_module('attention1_{}'.format(i), attention1)\n",
    "\n",
    "        self.attentions2 = [GraphAttentionLayer(\n",
    "            self.nhids[0] * self.nheads[0], self.nhids[1], dropout=dropout, alpha=alpha, concat=True) for _ in\n",
    "            range(self.nheads[1])]\n",
    "        for i, attention2 in enumerate(self.attentions2):\n",
    "            self.add_module('attention2_{}'.format(i), attention2)\n",
    "\n",
    "        self.attentions3 = [GraphAttentionLayer(\n",
    "            self.nhids[1] * self.nheads[1], self.nhids[2], dropout=dropout, alpha=alpha, concat=True) for _ in\n",
    "            range(self.nheads[2])]\n",
    "        for i, attention3 in enumerate(self.attentions3):\n",
    "            self.add_module('attention3_{}'.format(i), attention3)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "\n",
    "        self.pool1 = torch.nn.Linear(self.nhids[0] * self.nheads[0], 1)\n",
    "        self.pool2 = torch.nn.Linear(self.nhids[1] * self.nheads[1], 1)\n",
    "        self.pool3 = torch.nn.Linear(self.nhids[2] * self.nheads[2], 1)\n",
    "\n",
    "        lin_input_dim = 3 * self.dim\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(lin_input_dim, self.fc_dim[0]),\n",
    "            nn.ELU(),\n",
    "            nn.AlphaDropout(p=self.dropout, inplace=False))\n",
    "        self.fc1.apply(xavier_init)\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.fc_dim[0], self.fc_dim[1]),\n",
    "            nn.ELU(),\n",
    "            nn.AlphaDropout(p=self.dropout, inplace=False))\n",
    "        self.fc2.apply(xavier_init)\n",
    "\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(self.fc_dim[1], self.fc_dim[2]),\n",
    "            nn.ELU(),\n",
    "            nn.AlphaDropout(p=self.dropout, inplace=False))\n",
    "        self.fc3.apply(xavier_init)\n",
    "\n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(self.fc_dim[2], self.fc_dim[3]),\n",
    "            nn.ELU(),\n",
    "            nn.AlphaDropout(p=self.dropout, inplace=False))\n",
    "        self.fc4.apply(xavier_init)\n",
    "\n",
    "        self.fc5 = nn.Sequential(\n",
    "            nn.Linear(self.fc_dim[3], 2))\n",
    "        self.fc5.apply(xavier_init)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "\n",
    "\n",
    "        x0 = torch.mean(x, dim=-1)\n",
    "        x = self.dropout_layer(x)\n",
    "        x = torch.cat([att(x, adj) for att in self.attentions1], dim=-1)\n",
    "\n",
    "        x1 = self.pool1(x).squeeze(-1)\n",
    "        x = self.dropout_layer(x)\n",
    "        x = torch.cat([att(x, adj) for att in self.attentions2], dim=-1)\n",
    "\n",
    "        x2 = self.pool2(x).squeeze(-1)\n",
    "        x = torch.cat([x0, x1, x2], dim=1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x1 = self.fc3(x)\n",
    "        x = self.fc4(x1)\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        output = x1\n",
    "        gat_output = x\n",
    "\n",
    "        return output, gat_output\n",
    "\n",
    "\n",
    "class GraphAttentionLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super(GraphAttentionLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "\n",
    "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        self.a = nn.Parameter(torch.zeros(size=(2 * out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        \"\"\"\n",
    "        input: mini-batch input. size: [batch_size, num_nodes, node_feature_dim]\n",
    "        adj:   adjacency matrix. size: [num_nodes, num_nodes].  need to be expanded to batch_adj later.\n",
    "        \"\"\"\n",
    "        h = torch.matmul(input, self.W)\n",
    "        bs, N, _ = h.size()\n",
    "\n",
    "        a_input = torch.cat([h.repeat(1, 1, N).view(bs, N * N, -1), h.repeat(1, N, 1)], dim=-1).view(bs, N, -1,\n",
    "                                                                                                     2 * self.out_features)\n",
    "\n",
    "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(3))\n",
    "\n",
    "        batch_adj = torch.unsqueeze(adj, 0).repeat(bs, 1, 1)\n",
    "\n",
    "\n",
    "        zero_vec = -9e15 * torch.ones_like(e)\n",
    "        attention = torch.where(batch_adj > 0, e, zero_vec)\n",
    "        attention = self.dropout_layer(F.softmax(attention, dim=-1))  # [bs, N, N]\n",
    "        # print(\"attention shape:\", attention.shape)\n",
    "        h_prime = torch.bmm(attention, h)  # [bs, N, F]\n",
    "        # print(\"h_prime:\", h_prime.shape)\n",
    "\n",
    "        if self.concat:\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            return h_prime\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 601)\n",
      "(53, 601)\n",
      "torch.Size([161, 600])\n",
      "torch.Size([161])\n",
      "torch.Size([53, 600])\n",
      "torch.Size([53])\n",
      "torch.Size([200, 200])\n",
      "torch.Size([200, 200])\n",
      "torch.Size([200, 200])\n",
      " Epoch 0/2999\n",
      "200 3000\n",
      "----------\n",
      " Epoch 0/2999\n",
      "----------\n",
      "torch.Size([32, 600])\n",
      "tensor([3, 1, 2, 1, 3, 1, 0, 0, 3, 2, 1, 1, 0, 3, 3, 1, 0, 2, 1, 0, 2, 3, 2, 0,\n",
      "        2, 0, 3, 0, 3, 1, 3, 3])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 3 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 175\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mprint\u001b[39m(targets)\n\u001b[1;32m    165\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    166\u001b[0m (\n\u001b[1;32m    167\u001b[0m     loss_fusion,\n\u001b[1;32m    168\u001b[0m     tr_logits,\n\u001b[1;32m    169\u001b[0m     gat_output1,\n\u001b[1;32m    170\u001b[0m     gat_output2,\n\u001b[1;32m    171\u001b[0m     gat_output3,\n\u001b[1;32m    172\u001b[0m     output1,\n\u001b[1;32m    173\u001b[0m     output2,\n\u001b[1;32m    174\u001b[0m     output3,\n\u001b[0;32m--> 175\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_adj1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_adj2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_adj3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m tr_prob \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(tr_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    177\u001b[0m tr_pre_lab \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(tr_prob, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 82\u001b[0m, in \u001b[0;36mFusion.forward\u001b[0;34m(self, omic1, omic2, omic3, adj1, adj2, adj3, label, infer)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MMlogit\n\u001b[1;32m     81\u001b[0m MMLoss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(criterion(MMlogit, label))\n\u001b[0;32m---> 82\u001b[0m loss_gat1 \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgat_output1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m loss_gat2 \u001b[38;5;241m=\u001b[39m loss_function(gat_output2,label)\n\u001b[1;32m     84\u001b[0m loss_gat3 \u001b[38;5;241m=\u001b[39m loss_function(gat_output3,label)\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/torch/nn/modules/loss.py:1295\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/torch/nn/functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 3 is out of bounds."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "# from model_GBM import *\n",
    "\n",
    "# Env\n",
    "from utils import *\n",
    "import gc\n",
    "\n",
    "\n",
    "main_gremi = './train_test_1.py'\n",
    "data_dir = f'./TCGA_GBM_GExCNVxMETH_2000_MinMaxScaler/1'\n",
    "model_save_dir = f'./model-gbm1.pth'\n",
    "patience = 200\n",
    "tr_label='tr'\n",
    "te_label='te'\n",
    "batch_size=32\n",
    "\n",
    "# DATA\n",
    "# loaded_data = torch.load(data_dir)\n",
    "#\n",
    "data_tr = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(f\"{data_dir}/1_{tr_label}.csv\").iloc[:, :200],\n",
    "        pd.read_csv(f\"{data_dir}/2_{tr_label}.csv\").iloc[:, :200],\n",
    "        pd.read_csv(f\"{data_dir}/3_{tr_label}.csv\").iloc[:, :200],\n",
    "        pd.read_csv(f\"{data_dir}/labels_{tr_label}.csv\").iloc[:, :200],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "tr_omic = torch.tensor(data_tr.iloc[:, :-1].values, dtype=torch.float32)\n",
    "tr_labels = torch.tensor(data_tr.iloc[:, -1].values, dtype=torch.long)\n",
    "data_te = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(f\"{data_dir}/1_{te_label}.csv\").iloc[:, :200],\n",
    "        pd.read_csv(f\"{data_dir}/2_{te_label}.csv\").iloc[:, :200],\n",
    "        pd.read_csv(f\"{data_dir}/3_{te_label}.csv\").iloc[:, :200],\n",
    "        pd.read_csv(f\"{data_dir}/labels_{te_label}.csv\").iloc[:, :200],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "te_omic = torch.tensor(data_te.iloc[:, :-1].values, dtype=torch.float32)\n",
    "te_labels = torch.tensor(data_te.iloc[:, -1].values, dtype=torch.long)\n",
    "exp_adj1 = torch.tensor(\n",
    "    pd.read_csv(f\"{data_dir}/adj1.csv\", header=0, index_col=0).iloc[:200, :200].values, dtype=torch.float32\n",
    ")\n",
    "exp_adj2 = torch.tensor(\n",
    "    pd.read_csv(f\"{data_dir}/adj2.csv\", header=0, index_col=0).iloc[:200, :200].values, dtype=torch.float32\n",
    ")\n",
    "exp_adj3 = torch.tensor(\n",
    "    pd.read_csv(f\"{data_dir}/adj3.csv\", header=0, index_col=0).iloc[:200, :200].values, dtype=torch.float32\n",
    ")\n",
    "print(data_tr.shape)\n",
    "# print(data_tr.head())\n",
    "print(data_te.shape)\n",
    "# print(data_te.head())\n",
    "print(tr_omic.shape)\n",
    "# print(tr_omic)\n",
    "print(tr_labels.shape)\n",
    "# print(tr_labels)\n",
    "print(te_omic.shape)\n",
    "# print(te_omic)\n",
    "print(te_labels.shape)\n",
    "# print(te_labels)\n",
    "print(exp_adj1.shape)\n",
    "# print(exp_adj1)\n",
    "print(exp_adj2.shape)\n",
    "# print(exp_adj2)\n",
    "print(exp_adj3.shape)\n",
    "# print(exp_adj3)\n",
    "\n",
    "# DATA LOADRE\n",
    "tr_dataset = torch.utils.data.TensorDataset(tr_omic, tr_labels)\n",
    "tr_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=tr_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "te_dataset = torch.utils.data.TensorDataset(te_omic, te_labels)\n",
    "te_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=te_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "num_epochs = 3000\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "input_in_dim = [exp_adj1.shape[0], exp_adj2.shape[0], exp_adj3.shape[0]]\n",
    "input_hidden_dim = [64]\n",
    "network = Fusion(\n",
    "    num_class=4,\n",
    "    num_views=3,\n",
    "    hidden_dim=input_hidden_dim,\n",
    "    dropout=0.1,\n",
    "    in_dim=input_in_dim,\n",
    "    dim1=input_in_dim[0],\n",
    "    dim2=input_in_dim[1],\n",
    "    dim3=input_in_dim[2],\n",
    ")\n",
    "network.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.2)\n",
    "\n",
    "best_model_wts = copy.deepcopy(network.state_dict())\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "train_loss_all = []\n",
    "train_acc_all = []\n",
    "test_loss_all = []\n",
    "test_acc_all = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(0, num_epochs):\n",
    "    print(\" Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "    print(patience, num_epochs)\n",
    "    print(\"-\" * 10)\n",
    "    isPrint = epoch % 100 == 0\n",
    "    # Print epoch\n",
    "    if isPrint:\n",
    "        print(\" Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 10)\n",
    "    # Set current loss value\n",
    "    network.train()\n",
    "    current_loss = 0.0\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0\n",
    "    train_num = 0\n",
    "\n",
    "    for i, data in enumerate(tr_data_loader, 0):\n",
    "\n",
    "        batch_x, targets = data\n",
    "        print(batch_x.shape)\n",
    "        batch_x1 = batch_x[:, : input_in_dim[0]].reshape(-1, input_in_dim[0], 1)\n",
    "        batch_x2 = batch_x[:, input_in_dim[0] : -input_in_dim[2]].reshape(\n",
    "            -1, input_in_dim[1], 1\n",
    "        )\n",
    "        batch_x3 = batch_x[:, -input_in_dim[2] :].reshape(-1, input_in_dim[2], 1)\n",
    "\n",
    "        batch_x1 = batch_x1.to(torch.float32)\n",
    "        batch_x2 = batch_x2.to(torch.float32)\n",
    "        batch_x3 = batch_x3.to(torch.float32)\n",
    "        targets = targets.long()\n",
    "        batch_x1 = batch_x1.to(device)\n",
    "        batch_x2 = batch_x2.to(device)\n",
    "        batch_x3 = batch_x3.to(device)\n",
    "        targets = targets.to(device)\n",
    "        exp_adj1 = exp_adj1.to(device)\n",
    "        exp_adj2 = exp_adj2.to(device)\n",
    "        exp_adj3 = exp_adj3.to(device)\n",
    "        print(targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        (\n",
    "            loss_fusion,\n",
    "            tr_logits,\n",
    "            gat_output1,\n",
    "            gat_output2,\n",
    "            gat_output3,\n",
    "            output1,\n",
    "            output2,\n",
    "            output3,\n",
    "        ) = network(batch_x1, batch_x2, batch_x3, exp_adj1, exp_adj2, exp_adj3, targets)\n",
    "        tr_prob = F.softmax(tr_logits, dim=1)\n",
    "        tr_pre_lab = torch.argmax(tr_prob, 1)\n",
    "\n",
    "        loss = loss_fusion\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"3\")\n",
    "\n",
    "        train_loss += loss.item() * batch_x1.size(0)\n",
    "        train_corrects += torch.sum(tr_pre_lab == targets.data)\n",
    "        train_num += batch_x1.size(0)\n",
    "    # Evaluation for this fold\n",
    "    print(\"Trained\")\n",
    "    network.eval()\n",
    "    test_loss = 0.0\n",
    "    test_corrects = 0\n",
    "    test_num = 0\n",
    "    for i, data in enumerate(te_data_loader, 0):\n",
    "        batch_x, targets = data\n",
    "        batch_x1 = batch_x[:, : input_in_dim[0]].reshape(-1, input_in_dim[0], 1)\n",
    "        batch_x2 = batch_x[:, input_in_dim[0] : -input_in_dim[2]].reshape(\n",
    "            -1, input_in_dim[1], 1\n",
    "        )\n",
    "        batch_x3 = batch_x[:, -input_in_dim[2] :].reshape(-1, input_in_dim[2], 1)\n",
    "        batch_x1 = batch_x1.to(torch.float32)\n",
    "        batch_x2 = batch_x2.to(torch.float32)\n",
    "        batch_x3 = batch_x3.to(torch.float32)\n",
    "        targets = targets.long()\n",
    "        batch_x1 = batch_x1.to(device)\n",
    "        batch_x2 = batch_x2.to(device)\n",
    "        batch_x3 = batch_x3.to(device)\n",
    "        targets = targets.to(device)\n",
    "        exp_adj1 = exp_adj1.to(device)\n",
    "        exp_adj2 = exp_adj2.to(device)\n",
    "        exp_adj3 = exp_adj3.to(device)\n",
    "\n",
    "        te_logits = network.infer(\n",
    "            batch_x1, batch_x2, batch_x3, exp_adj1, exp_adj2, exp_adj3\n",
    "        )\n",
    "        te_prob = F.softmax(te_logits, dim=1)\n",
    "        te_pre_lab = torch.argmax(te_prob, 1)\n",
    "\n",
    "        test_corrects += torch.sum(te_pre_lab == targets.data)\n",
    "        test_num += batch_x1.size(0)\n",
    "\n",
    "    train_loss_all.append(train_loss / train_num)\n",
    "    train_acc_all.append(train_corrects.double().item() / train_num)\n",
    "    test_acc_all.append(test_corrects.double().item() / test_num)\n",
    "    print(\"Tested\")\n",
    "    if isPrint:\n",
    "        print(\n",
    "            \"{} Train Loss : {:.8f} Train ACC : {:.8f}\".format(\n",
    "                epoch, train_loss_all[-1], train_acc_all[-1]\n",
    "            )\n",
    "        )\n",
    "        print(\"{}  Test ACC : {:.8f}\".format(epoch, test_acc_all[-1]))\n",
    "\n",
    "    if test_acc_all[-1] > best_acc:\n",
    "        best_acc = test_acc_all[-1]\n",
    "        best_epoch = epoch + 1\n",
    "        best_model_wts = copy.deepcopy(network.state_dict())\n",
    "        early_stopping_counter = 0\n",
    "        # Saving the model\n",
    "        save_path = model_save_dir\n",
    "        state = {\n",
    "            \"net\": best_model_wts,\n",
    "        }\n",
    "        torch.save(state, save_path)\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "        print(f\"Best test accuracy: {best_acc}\")\n",
    "        print(f\"Best test epoch: {best_epoch}\")\n",
    "        break\n",
    "print(\"end\")\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_all, \"ro-\", label=\"Train loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Best test epoch: {0}\".format(best_epoch - 1))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc_all, \"ro-\", label=\"Train acc\")\n",
    "plt.plot(test_acc_all, \"bs-\", label=\"Test acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.title(\"Best test Acc: {0}\".format(best_acc))\n",
    "plt.legend()\n",
    "plt.savefig(\"/kaggle/working/total_loss.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T04:01:07.244888Z",
     "iopub.status.busy": "2025-02-16T04:01:07.244084Z",
     "iopub.status.idle": "2025-02-16T04:03:27.899704Z",
     "shell.execute_reply": "2025-02-16T04:03:27.898194Z",
     "shell.execute_reply.started": "2025-02-16T04:01:07.244863Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      " Epoch 0/2999\n",
      "200 3000\n",
      "----------\n",
      " Epoch 0/2999\n",
      "----------\n",
      "2\n",
      " Epoch 0/2999\n",
      "200 3000\n",
      "----------\n",
      " Epoch 0/2999\n",
      "----------\n",
      "3\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'child' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/IPython/utils/_process_posix.py:151\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     child \u001b[38;5;241m=\u001b[39m \u001b[43mpexpect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Vanilla Pexpect\u001b[39;00m\n\u001b[1;32m    152\u001b[0m flush \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/pexpect/pty_spawn.py:205\u001b[0m, in \u001b[0;36mspawn.__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_poll \u001b[38;5;241m=\u001b[39m use_poll\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/pexpect/pty_spawn.py:303\u001b[0m, in \u001b[0;36mspawn._spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m a\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n\u001b[1;32m    301\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawnpty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc\u001b[38;5;241m.\u001b[39mpid\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/pexpect/pty_spawn.py:315\u001b[0m, in \u001b[0;36mspawn._spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mptyprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPtyProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/ptyprocess/ptyprocess.py:315\u001b[0m, in \u001b[0;36mPtyProcess.spawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions, pass_fds)\u001b[0m\n\u001b[1;32m    314\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(exec_err_pipe_write)\n\u001b[0;32m--> 315\u001b[0m exec_err_data \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_err_pipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(exec_err_pipe_read)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m te_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mte\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython \u001b[39;49m\u001b[38;5;132;43;01m{main_gremi}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{data_dir}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{model_save_dir}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{patience}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{tr_label}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{te_label}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{batch_size}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# display(Image(\"/kaggle/working/total_loss.png\"))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/loilon504/lib/python3.13/site-packages/IPython/utils/_process_posix.py:167\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    162\u001b[0m         out_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# We need to send ^C to the process.  The ascii code for '^C' is 3\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# (the character is known as ETX for 'End of Text', see\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# curses.ascii.ETX).\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241m.\u001b[39msendline(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Read and print any more output the program might produce on its\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# way out.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'child' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    print(i)\n",
    "    main_gremi = './train_test_1.py'\n",
    "    data_dir = f'./TCGA_GBM_GExCNVxMETH_2000_MinMaxScaler/{i}'\n",
    "    model_save_dir = f'./model-gbm{i}.pth'\n",
    "    patience = 200\n",
    "    tr_label='tr'\n",
    "    te_label='te'\n",
    "    batch_size=32\n",
    "    !python {main_gremi} '{data_dir}' '{model_save_dir}' '{patience}' '{tr_label}' '{te_label}' '{batch_size}'\n",
    "    \n",
    "    # display(Image(\"/kaggle/working/total_loss.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-16T04:26:38.838Z",
     "iopub.execute_input": "2025-02-16T04:03:27.901739Z",
     "iopub.status.busy": "2025-02-16T04:03:27.901377Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/gremi-ori/train_test_0.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load(data_dir)\n",
      " Epoch 0/2999\n",
      "----------\n",
      "0 Train Loss : 8.88440137 Train ACC : 0.55918367\n",
      "0  Test ACC : 0.51886792\n"
     ]
    }
   ],
   "source": [
    "# %cd /kaggle/input/gremi-ori/ROSMAP\n",
    "# !python model_test_rosmap.py\n",
    "\n",
    "main_gremi = '/kaggle/input/gremi-ori/train_test_0.py'\n",
    "data_dir = '/kaggle/input/gremi-ori/ROSMAP/data.pt'\n",
    "model_save_dir = '/kaggle/working/model-rosmap1.pth'\n",
    "patience = 100\n",
    "!python {main_gremi} '{data_dir}' '{model_save_dir}' '{patience}'\n",
    "\n",
    "display(Image(\"/kaggle/working/total_loss.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-16T04:26:38.838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/input/gremi-ori/BRCA\n",
    "!python model_test_0.py\n",
    "\n",
    "# main_gremi = '/kaggle/input/gremi-ori/train_test_0.py'\n",
    "# data_dir = '/kaggle/input/gremi-ori/BRCA/data.pt'\n",
    "# model_save_dir = '/kaggle/working/model-brca1.pth'\n",
    "# patience = 100\n",
    "# !python {main_gremi} '{data_dir}' '{model_save_dir}' '{patience}'\n",
    "\n",
    "# display(Image(\"/kaggle/working/total_loss.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-16T04:26:38.838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/input/gremi-ori/in-house data/LUAD\n",
    "# !python train_test_0.py\n",
    "main_gremi = '/kaggle/input/gremi-ori/train_test_0.py'\n",
    "data_dir = '/kaggle/input/gremi-ori/in-house data/LUAD/data.pt'\n",
    "model_save_dir = '/kaggle/working/model-luad1.pth'\n",
    "patience = 100\n",
    "!python {main_gremi} '{data_dir}' '{model_save_dir}' '{patience}'\n",
    "\n",
    "display(Image(\"/kaggle/working/total_loss.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-16T04:26:38.838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "main_gremi = '/kaggle/input/gremi-ori/train_test_0.py'\n",
    "data_dir = '/kaggle/input/gremi-ori/in-house data/THCA/data.pt'\n",
    "model_save_dir = '/kaggle/working/model-thca1.pth'\n",
    "patience = 100\n",
    "!python {main_gremi} '{data_dir}' '{model_save_dir}' '{patience}'\n",
    "\n",
    "display(Image(\"/kaggle/working/total_loss.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-16T04:26:38.838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "main_gremi = '/kaggle/input/gremi-ori/train_test_0.py'\n",
    "data_dir = '/kaggle/input/gremi-ori/in-house data/UCEC/data.pt'\n",
    "model_save_dir = '/kaggle/working/model-ucec1.pth'\n",
    "patience = 100\n",
    "!python {main_gremi} '{data_dir}' '{model_save_dir}' '{patience}'\n",
    "\n",
    "display(Image(\"/kaggle/working/total_loss.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-16T04:26:38.838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/input/gremi-ori/explain\n",
    "# !python mutag_sub_demo.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6654910,
     "sourceId": 10733371,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6630331,
     "sourceId": 10760940,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "loilon504",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
